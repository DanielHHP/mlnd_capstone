
《【干货】一文搞懂现代情感分析方法》
https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&mid=2247486742&idx=1&sn=3cb49059f0fe6f8f59d7ce4fd2bab8e6&chksm=ebb435c2dcc3bcd41bd39a167542c81585cd00fd2e8968a9e100ce6cb11b5881b9786b480bcd&mpshare=1&scene=1&srcid=0107HYaF8ZAPNnLrNaVpOOy1&pass_ticket=1dUOLvMiiVIQJCfR2bDqnEiGBHrBjHd3r5h4Qzm2miNJQANqtRhnVrK164Zvx7FK#rd

sklearn 20 newsgroup
http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html
http://scikit-learn.org/stable/datasets/twenty_newsgroups.html
http://scikit-learn.org/stable/datasets/#filtering-text-for-more-realistic-training
http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#sphx-glr-auto-examples-text-document-classification-20newsgroups-py
http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py

stanford Classifier
https://nlp.stanford.edu/wiki/Software/Classifier/20_Newsgroups

keras examples
https://github.com/keras-team/keras/tree/master/examples

fasttext
http://www.algorithmdog.com/fast-fasttext

基于 word2vec 和 CNN 的文本分类 ：综述 & 实践
https://zhuanlan.zhihu.com/p/29076736


Character-level Convolutional Networks for Text
ClassificationEfficient Character-level Document Classification by
Combining Convolution and Recurrent LayersVery Deep Convolutional Networks
for Natural Language Processing

作者：Weijie Huang
链接：https://www.zhihu.com/question/48688908/answer/114442523
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。


[深度学习在文本分类中的应用]
(https://mp.weixin.qq.com/s?__biz=MzI0OTQyNzEzMQ==&mid=2247486054&idx=1&sn=713b0cb002bf0f5ac216203dafc2e5ec&chksm=e990efb2dee766a4713a4ae78b6988345b292f8580b3fc1aec75e7309c0b61c5b65f53d96646&mpshare=1&scene=1&srcid=0126HK5wBsDbGNyCMw7MDSD3&pass_ticket=55wTuOPK3Xxt81W2F259MyGam6ooh4JanP1wUPxGH5ed2v6WFpHhi1bCM7EegfYS#rd)


[基于上下文的文本分类]
https://www.atatech.org/articles/98876/?flag_data_from=mail_daily_recommend&uid=24652


tensorflow 训练word2vec
https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/examples/tutorials/word2vec/word2vec_basic.py

gensim：关于 word2vec 模型的训练与效果对比
http://blog.imaou.com/opensource/2015/08/31/how_to_train_word2vec.html
默认sg=1是skip-gram算法，对低频词敏感；不过这里因为是计算近似词所以要选择CBOW(sg=0)；

kaggel NLP kernels
https://www.kaggle.com/c/spooky-author-identification/kernels


char cnn代码例子
https://github.com/purzelrakete/char-cnn/tree/master/charcnn

如何解决90％的自然语言处理问题：分步指南奉上
https://mp.weixin.qq.com/s?__biz=MzI4MDYzNzg4Mw==&mid=2247486933&idx=2&sn=ee86f1153852e2b79034a33d4d995c96&chksm=ebb43501dcc3bc172192afdb7d461eb1fdc5f4b7c20808bdc23eee6626ce4e1ce78c8cf4bcbf&mpshare=1&scene=1&srcid=0131Si6VGMBlIyQ0DKmPqWlz&pass_ticket=Jhrry0hh%2Bkmyt7cJ%2Bx5eygxGUb0R%2Ft2a1d4ZXR7gjPc%2Fv%2FHkWY1acKpYbpPRDqkJ#rd
子文章：https://medium.freecodecamp.org/big-picture-machine-learning-classifying-text-with-neural-networks-and-tensorflow-d94036ac2274
https://github.com/hundredblocks/concrete_NLP_tutorial/blob/master/NLP_notebook.ipynb

lime模型解释
https://github.com/marcotcr/lime
